---
title: 'RAPHAEL:Text-to-Image Generation via Large Mixture of Diffusion Paths'
date: 2024-05-16
permalink: /posts/2024/05/raphael
tags:
  - raphael
  - diffusion model
  - Mixture of Experts
---

In recent years Generative Artificial Intelligence has gained a lot of popularity and usage in our daily lives. Image Generation became popular with models like Stable Diffusion or DALL-E which showed the public what Image Generation is able to do. In this blog post, I aim to introduce and explain a new model, RAPHAEL, which outperforms models like Stable Diffusion and focuses on accurately displaying text in the generated images.

Why image generation?
======

How to map image generation to a Deep Learning problem
======

Input 
------

Output
------

Loss function
------

RAPHAEL Architecture
======

Comparison to Stable Diffusion
------

What are Mixture of Experts?
------

What are Space-MoE?
------

What are Time-MoE?
------

What is Edge-supervised Learning
------

Experiments and Benchmarks
======

Discussion
======
